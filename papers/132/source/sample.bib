
@article{10.1145/3641289,
author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
title = {A Survey on Evaluation of Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3641289},
doi = {10.1145/3641289},
abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at:},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
articleno = {39},
numpages = {45},
keywords = {Large language models, evaluation, model assessment, benchmark}
}

@misc{naveed2024comprehensiveoverviewlargelanguage,
      title={A Comprehensive Overview of Large Language Models}, 
      author={Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
      year={2024},
      eprint={2307.06435},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.06435}, 
}

@article{10.1145/3624724,
author = {Shanahan, Murray},
title = {Talking about Large Language Models},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624724},
doi = {10.1145/3624724},
abstract = {Interacting with a contemporary LLM-based conversational agent can create an illusion of being in the presence of a thinking creature. Yet, in their very nature, such systems are fundamentally not like us.},
journal = {Commun. ACM},
month = jan,
pages = {68–79},
numpages = {12}
}

@misc{wei2022emergentabilitieslargelanguage,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}

@article{albashrawi2025generative,
  title={Generative AI for decision-making: A multidisciplinary perspective},
  author={Albashrawi, Mousa},
  journal={Journal of Innovation \& Knowledge},
  volume={10},
  number={4},
  pages={100751},
  year={2025},
  publisher={Elsevier}
}

@article{malloy2024applying,
  title={Applying Generative Artificial Intelligence to cognitive models of decision making},
  author={Malloy, Tyler and Gonzalez, Cleotilde},
  journal={Frontiers in Psychology},
  volume={15},
  pages={1387948},
  year={2024},
  publisher={Frontiers Media SA}
}

@article{thirunavukarasu2023large,
  title={Large language models in medicine},
  author={Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal={Nature medicine},
  volume={29},
  number={8},
  pages={1930--1940},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{yang2025retrieval,
  title={Retrieval-augmented generation for generative artificial intelligence in health care},
  author={Yang, Rui and Ning, Yilin and Keppo, Emilia and Liu, Mingxuan and Hong, Chuan and Bitterman, Danielle S and Ong, Jasmine Chiat Ling and Ting, Daniel Shu Wei and Liu, Nan},
  journal={npj Health Systems},
  volume={2},
  number={1},
  pages={2},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{cascella2023evaluating,
  title={Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios},
  author={Cascella, Marco and Montomoli, Jonathan and Bellini, Valentina and Bignami, Elena},
  journal={Journal of medical systems},
  volume={47},
  number={1},
  pages={33},
  year={2023},
  publisher={Springer}
}

@article{fang2024bias,
  title={Bias of AI-generated content: an examination of news produced by large language models},
  author={Fang, Xiao and Che, Shangkun and Mao, Minjia and Zhang, Hongzhe and Zhao, Ming and Zhao, Xiaohang},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={5224},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{tao2024cultural,
  title={Cultural bias and cultural alignment of large language models},
  author={Tao, Yan and Viberg, Olga and Baker, Ryan S and Kizilcec, Ren{\'e} F},
  journal={PNAS nexus},
  volume={3},
  number={9},
  pages={pgae346},
  year={2024},
  publisher={Oxford University Press US}
}

@article{naous2023having,
  title={Having beer after prayer? measuring cultural bias in large language models},
  author={Naous, Tarek and Ryan, Michael J and Ritter, Alan and Xu, Wei},
  journal={arXiv preprint arXiv:2305.14456},
  year={2023}
}

@article{hu2025generative,
  title={Generative language models exhibit social identity biases},
  author={Hu, Tiancheng and Kyrychenko, Yara and Rathje, Steve and Collier, Nigel and van der Linden, Sander and Roozenbeek, Jon},
  journal={Nature Computational Science},
  volume={5},
  number={1},
  pages={65--75},
  year={2025},
  publisher={Nature Publishing Group US New York}
}

@article{bai2025explicitly,
  title={Explicitly unbiased large language models still form biased associations},
  author={Bai, Xuechunzi and Wang, Angelina and Sucholutsky, Ilia and Griffiths, Thomas L},
  journal={Proceedings of the National Academy of Sciences},
  volume={122},
  number={8},
  pages={e2416228122},
  year={2025},
  publisher={National Academy of Sciences}
}

@article{meade2021empirical,
  title={An empirical survey of the effectiveness of debiasing techniques for pre-trained language models},
  author={Meade, Nicholas and Poole-Dayan, Elinor and Reddy, Siva},
  journal={arXiv preprint arXiv:2110.08527},
  year={2021}
}

@article{gerych2023debiasing,
  title={Debiasing pretrained generative models by uniformly sampling semantic attributes},
  author={Gerych, Walter and Hickey, Kevin and Buquicchio, Luke and Chandrasekaran, Kavin and Alajaji, Abdulaziz and Rundensteiner, Elke A and Agu, Emmanuel},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={45083--45101},
  year={2023}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}
@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}
@misc{grok3beta,
  title={beta—the age of reasoning agents},
  author={Grok, XAI},
  year={3}
}

@article{mcknight2010mann,
  title={Mann-whitney U test},
  author={McKnight, Patrick E and Najab, Julius},
  journal={The Corsini encyclopedia of psychology},
  pages={1--1},
  year={2010},
  publisher={Wiley Online Library}
}

@article{mann1947test,
  title={On a test of whether one of two random variables is stochastically larger than the other},
  author={Mann, Henry B and Whitney, Donald R},
  journal={The annals of mathematical statistics},
  pages={50--60},
  year={1947},
  publisher={JSTOR}
}

@article{virtanen2020scipy,
  title={SciPy 1.0: fundamental algorithms for scientific computing in Python},
  author={Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and others},
  journal={Nature methods},
  volume={17},
  number={3},
  pages={261--272},
  year={2020},
  publisher={Nature Publishing Group US New York}
}

@online{anthropic_claude4,
  author       = {{Anthropic}},
  title        = {Introducing Claude 4},
  year         = {2025},
  month        = may,
  day          = 22,
  url          = {https://www.anthropic.com/news/claude-4},
  note         = {Accessed: 7 September 2025}
}

@online{openai_gpt4.1,
  author    = {{OpenAI}},
  title     = {Introducing GPT-4.1 in the API},
  year      = {2025},
  month     = apr,
  day       = 14,
  url       = {https://openai.com/index/gpt-4-1/},
  note      = {Accessed: 7 September 2025}
}

@online{xai_grok3_beta,
  author       = {{xAI}},
  title        = {Grok 3 Beta — The Age of Reasoning Agents},
  year         = {2025},
  month        = feb,
  day          = 19,
  url          = {https://x.ai/news/grok-3},
  note         = {Accessed: 7 September 2025}
}

@online{perplexity_getting_started,
  author    = {{Perplexity Team}},
  title     = {Getting started with Perplexity},
  year      = {2024},
  month     = oct,
  day       = 1,
  url       = {https://www.perplexity.ai/hub/blog/getting-started-with-perplexity},
  note      = {Accessed: 7 September 2025}
}

@online{mistral_lechat_2025,
  author       = {{Mistral AI Team}},
  title        = {The all new le Chat: Your AI assistant for life and work},
  year         = {2025},
  month        = feb,
  day          = 6,
  url          = {https://mistral.ai/news/all-new-le-chat?ref=mail.bycloud.ai},
  note         = {Accessed: 7 September 2025}
}

@online{meta_llama4_2025,
  author    = {{Meta AI}},
  title     = {The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation},
  year      = {2025},
  month     = apr,
  day       = 5,
  url       = {https://ai.meta.com/blog/llama-4-multimodal-intelligence/},
  note      = {Accessed: 7 September 2025}
}
