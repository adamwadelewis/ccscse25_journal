
@article{RASHID2024100277,
title = {AI revolutionizing industries worldwide: A comprehensive overview of its diverse applications},
journal = {Hybrid Advances},
volume = {7},
pages = {100277},
year = {2024},
issn = {2773-207X},
doi = {https://doi.org/10.1016/j.hybadv.2024.100277},
url = {https://www.sciencedirect.com/science/article/pii/S2773207X24001386},
author = {Adib Bin Rashid and MD Ashfakul Karim Kausik},
keywords = {Artificial intelligence (AI), Industry 4.0, Industry 5.0, Machine learning, Deep learning, Autonomous system, Surveillance},
abstract = {Artificial Intelligence (AI) technology's rapid advancement has significantly changed various industries' operations. This comprehensive review paper aims to provide readers with a deep understanding of AI's applications & implementations, workings, and potential impacts across different sectors. It also discusses its future, threats, and integration into new policy. Through extensive research on more than 200 research and many other sources, the authors have made every effort to present an accurate overview of the numerous applications of AI nowadays in industries such as agriculture, education, autonomous systems, healthcare, finance, entertainment, transportation, military, manufacturing, and more. The paper explores various AI technologies, including machine learning, deep learning, robotics, big data, the Internet of Things, natural language processing, image processing, object detection, virtual reality, augmented reality, speech recognition, and computer vision. It provides real-world examples of their applications and implementations. Moreover, it highlights and evaluates the future potential, challenges, and limitations associated with the widespread use of AI. Our study incorporates the latest research to offer a comprehensive and nuanced understanding of AI's potential benefits and challenges. This data-driven review case study highlights the immense potential of AI technology and addresses the ethical, societal, and economic considerations related to its implementation.}
}

@article{MANORAT2025100403,
title = {Artificial intelligence in computer programming education: A systematic literature review},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100403},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100403},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000438},
author = {Pisut Manorat and Suppawong Tuarob and Siripen Pongpaichet},
keywords = {Artificial intelligence, Machine learning, Computer programming education, Systematic literature review},
abstract = {The demand for skilled programmers and the increasing complexity of coding skills have led to a rise in the adoption of artificial intelligence (AI) and machine learning (ML) technologies in computer programming education. Previous research has explored the potential of AI in aspects such as grading assignments, generating feedback, detecting plagiarism, and identifying at-risk students, but there is a lack of systematic reviews focused on AI-powered teaching processes in computer programming classes. To provide a more comprehensive understanding of AI and ML's role in computer programming education, this systematic review examines a wider range of applications across the entire pedagogical process. Analyzing 119 relevant research papers published between 2012 and 2024, this review offers an overview of AI and ML tools and techniques used in various educational contexts. Aligned with instructional design models, the reviewed literature is categorized into four key areas: course design, classroom implementation, assessment and feedback, and performance monitoring. This systematic review not only highlights the practical tools available to instructors but also identifies research trends and potential areas for future exploration in the field of computer programming education.}
}

@inproceedings{banit,
author = {Lau, Sam and Guo, Philip},
title = {From "Ban It Till We Understand It" to "Resistance is Futile": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600138},
doi = {10.1145/3568813.3600138},
abstract = {Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {106–121},
numpages = {16},
keywords = {AI coding tools, ChatGPT, Copilot, LLM, instructor perspectives},
location = {Chicago, IL, USA},
series = {ICER '23}
}



@misc{kaup2024reviewphysicsenginesreinforcement,
      title={A Review of Nine Physics Engines for Reinforcement Learning Research}, 
      author={Michael Kaup and Cornelius Wolff and Hyerim Hwang and Julius Mayer and Elia Bruni},
      year={2024},
      eprint={2407.08590},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.08590} 
}

@Article{Jiao2024,
author={Jiao, Licheng
and Song, Xue
and You, Chao
and Liu, Xu
and Li, Lingling
and Chen, Puhua
and Tang, Xu
and Feng, Zhixi
and Liu, Fang
and Guo, Yuwei
and Yang, Shuyuan
and Li, Yangyang
and Zhang, Xiangrong
and Ma, Wenping
and Wang, Shuang
and Bai, Jing
and Hou, Biao},
title={AI meets physics: a comprehensive survey},
journal={Artificial Intelligence Review},
year={2024},
month={Aug},
day={16},
volume={57},
number={9},
pages={256},
abstract={Uncovering the mechanisms of physics is driving a new paradigm in artificial intelligence (AI) discovery. Today, physics has enabled us to understand the AI paradigm in a wide range of matter, energy, and space-time scales through data, knowledge, priors, and laws. At the same time, the AI paradigm also draws on and introduces the knowledge and laws of physics to promote its own development. Then this new paradigm of using physical science to inspire AI is the physical science of artificial intelligence (PhysicsScience4AI, PS4AI). Although AI has become the driving force for development in various fields, there is still a ``black box'' phenomenon that is difficult to explain in the field of AI deep learning. This article will briefly review the connection between relevant physics disciplines (classical mechanics, electromagnetism, statistical physics, quantum mechanics) and AI. It will focus on discussing the mechanisms of physics disciplines and how they inspire the AI deep learning paradigm, and briefly introduce some related work on how AI solves physics problems. PS4AI is a new research field. At the end of the article, we summarize the challenges facing the new physics-inspired AI paradigm and look forward to the next generation of artificial intelligence technology. This article aims to provide a brief review of research related to physics-inspired AI deep algorithms and to stimulate future research and exploration by elucidating recent advances in physics.},
issn={1573-7462},
doi={10.1007/s10462-024-10874-4},
url={https://doi.org/10.1007/s10462-024-10874-4}
}

@article{Ali-Dib_2024,
doi = {10.1088/1402-4896/ad7a27},
url = {https://dx.doi.org/10.1088/1402-4896/ad7a27},
year = {2024},
month = {oct},
publisher = {IOP Publishing},
volume = {99},
number = {11},
pages = {116003},
author = {Ali-Dib, Mohamad and Menou, Kristen},
title = {Physics simulation capabilities of LLMs},
journal = {Physica Scripta},
abstract = {Large Language Models (LLMs) can solve some undergraduate-level to graduate-level physics textbook problems and are proficient at coding. Combining these two capabilities could one day enable AI systems to simulate and predict the physical world. We present an evaluation of state-of-the-art (SOTA) LLMs on PhD-level to research-level computational physics problems. We condition LLM generation on the use of well-documented and widely-used packages to elicit coding capabilities in the physics and astrophysics domains. We contribute ∼50 original and challenging problems in celestial mechanics (with REBOUND), stellar physics (with MESA), 1D fluid dynamics (with Dedalus) and non-linear dynamics (with SciPy). Since our problems do not admit unique solutions, we evaluate LLM performance on several soft metrics: counts of lines that contain different types of errors (coding, physics, necessity and sufficiency) as well as a more educational’ Pass-Fail metric focused on capturing the salient physical ingredients of the problem at hand. As expected, today's SOTA LLM (GPT4) zero-shot fails most of our problems, although about 40\% of the solutions could plausibly get a passing grade. About 70\%–90\% of the code lines produced are necessary, sufficient and correct (coding &amp; physics). Physics and coding errors are the most common, with some unnecessary or insufficient lines. We observe significant variations across problem class and difficulty. We identify several failure modes of GPT4 in the computational physics domain, such as poor physical units handling, poor code versioning, tendency to hallucinate plausible sub-modules, lack of physical justification for global run parameters (e.g., simulation time, or upper-lower bounds for parametric exploration) and inability to define steady-state or stopping conditions reliably. Our reconnaissance work provides a snapshot of current computational capabilities in classical physics and points to obvious improvement targets if AI systems are ever to reach a basic level of autonomy in physics simulation capabilities.}
}

@Article{Misic2024,
author={Mi{\v{s}}i{\'{c}}, Marko
and Dodovi{\'{c}}, Matija},
title={An assessment of large language models for OpenMP-based code parallelization: a user perspective},
journal={Journal of Big Data},
year={2024},
month={Nov},
day={10},
volume={11},
number={1},
pages={161},
abstract={Large language models have sparked a lot of attention in the research community in recent days, especially with the introduction of practical tools such as ChatGPT and Github Copilot. Their ability to solve complex programming tasks was also shown in several studies and commercial solutions increasing the interest in using them for software development in different fields. High performance computing is one of such fields, where parallel programming techniques have been extensively used to utilize raw computing power available in contemporary multicore and manycore processors. In this paper, we perform an evaluation of the ChatGPT and Github Copilot tools for OpenMP-based code parallelization using a proposed methodology. We used nine different benchmark applications which represent typical parallel programming workloads and compared their OpenMP-based parallel solutions produced manually and using ChatGPT and Github Copilot in terms of obtained speedup, applied optimizations, and quality of the solution. ChatGPT 3.5 and Github Copilot installed with Visual Studio Code 1.88 were used. We concluded that both tools can produce correct parallel code in most cases. However, performance-wise, ChatGPT can match manually produced and optimized parallel code only in simpler cases, as it lacks a deeper understanding of the code and the context. The results are much better with Github Copilot, where much less effort is needed to obtain correct and performant parallel solution.},
issn={2196-1115},
doi={10.1186/s40537-024-01019-z},
url={https://doi.org/10.1186/s40537-024-01019-z}
}

@inproceedings{ding2023hpc,
  title={Hpc-gpt: Integrating large language model for high-performance computing},
  author={Ding, Xianzhong and Chen, Le and Emani, Murali and Liao, Chunhua and Lin, Pei-Hung and Vanderbruggen, Tristan and Xie, Zhen and Cerpa, Alberto and Du, Wan},
  booktitle={Proceedings of the SC'23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis},
  pages={951--960},
  year={2023}
}

@inproceedings{martins2025llm,
  title={An LLM-Enhanced Framework for Bridging Simulators and Game Engines towards Realistic 3D Simulations},
  author={Martins de Freitas Cintra, Luiza and de Oliveira, Elisa Ayumi Masasi and Sousa, Rafael Teixeira and Graciano, Valdemar Vicente and Galv{\~a}o, Arlindo and Webster, Gustavo and da Costa Paiva, Sofia Larissa},
  booktitle={Proceedings of the 2025 ACM International Conference on Interactive Media Experiences},
  pages={402--405},
  year={2025}
}

@article{BATCHELORMCAULEY2020114607,
title = {Diffusion to a cube: A 3D implicit finite difference method},
journal = {Journal of Electroanalytical Chemistry},
volume = {877},
pages = {114607},
year = {2020},
issn = {1572-6657},
doi = {https://doi.org/10.1016/j.jelechem.2020.114607},
url = {https://www.sciencedirect.com/science/article/pii/S1572665720308353},
author = {Christopher Batchelor-McAuley and Richard G. Compton},
keywords = {Chronoamperometry, Backward implicit simulation, Nanocubes, GPGPU},
abstract = {We report the diffusional mass-transport to an isolated cube and numerically determine both the steady-state and the chronoamperometric flux, the latter at both short and long timescales. It is found that across a wide range of timescales the total flux is well approximated (to within 5\% error) by the response expected for a sphere of equivalent surface area where the equivalent radius is equal to 1.38 times the half side length of the cube. Under steady-state conditions the size of the equivalent sphere is marginally smaller (equivalent radius 1.34). However, the prime difference between the flux to a cube and a sphere is that in the case of a cube the steady-state flux density across the particle is non-uniform. Towards the cubic particle edges the flux density increases asymptotically. This numerical study was undertaken using a graphics processor unit solving the diffusion equation using a 3D finite difference fully backward implicit scheme. The results are of interest to current-time responses seen in single nanoparticle experiments where non spherical shapes are frequently encountered.}
}

@misc{Mathematica,
  author = {Wolfram Research{,} Inc.},
  title = {Mathematica, {V}ersion 14.2},
  url = {https://www.wolfram.com/mathematica},
  note = {Champaign, IL, 2024}
}

@misc{GoogleAI2025,
  author = {{Google AI}},
  title = {{Gemini conversational AI model, Version 2.5 Flash}},
  howpublished = {Chat with Gemini},
  year = {2025},
  note = {Accessed June 11, 2025},
  url = {https://gemini.google.com/}
}

@book{chapman2007using,
  title={Using OpenMP: portable shared memory parallel programming},
  author={Chapman, Barbara and Jost, Gabriele and Van Der Pas, Ruud},
  year={2007},
  publisher={MIT press}
}

@misc{openacc,
    author={OpenACC},
    title={OpenACC, Directives for Accelerators},
    url={http://www.openacc.org/}
}

@book{tinoco,
    title = {Physical Chemistry: Principles and Applications in Biological Sciences},
    edition = {5th},
    author = {Tinoco, Ignacio and Sauer, Kenneth and Wang, James C. and Puglisi, Joseph D. and
       Harbison, Gerard and Rovnyak, David},
    year = {2014},
    publisher = {Pearson Education}
} 

@book{hager,
    author = {Hager, Georg and Wellein, Gerhard},
    title={Introduction to High Performance Computing for Scientists and Engineers},
    edition={1st},
    publisher={CRC Press},
    doi={https://doi.org/10.1201/EBK1439811924}
}
            year={2010}
